{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage, spatial\n",
    "import transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointDetector(object):\n",
    "    def detectKeypoints(self, image):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image with pixel values in [0, 255].\n",
    "        Output:\n",
    "          - A list of detected keypoints. Each keypoint should be a cv2.KeyPoint object with:\n",
    "              • pt: (x, y) coordinates,\n",
    "              • angle: gradient orientation (in degrees),\n",
    "              • response: detector response (e.g. Harris score),\n",
    "              • size: set to 10.\n",
    "        \"\"\"\n",
    "        return HarrisKeypointDetector.detectKeypoints(self,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyKeypointDetector(KeypointDetector):\n",
    "    \"\"\"\n",
    "    A silly detector that generates dummy keypoints based on an arbitrary condition.\n",
    "    \"\"\"\n",
    "    def detectKeypoints(self, image):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "        Output:\n",
    "          - List of cv2.KeyPoint objects.\n",
    "        Hint:\n",
    "          - Iterate over every pixel.\n",
    "          - Use a simple condition (e.g., based on the sum of the channels modulo a constant)\n",
    "            to decide whether to create a keypoint.\n",
    "        \"\"\"\n",
    "        # TODO: Implement dummy keypoint detection according to the hint.\n",
    "        image_float32 = image.astype(np.float32) / 255\n",
    "        image_gray = cv2.cvtColor(image_float32,cv2.COLOR_BGR2GRAY)\n",
    "        harris,grad = self.computeHarrisValues(image_gray)\n",
    "\n",
    "        height,width = image.shape\n",
    "\n",
    "        keypoints = []\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "              if (image[i][j][0]+image[i][j][1]+image[i][j][2]) % 2 == 1:\n",
    "                  temp_keypoint = cv2.KeyPoint(x=j, y=i, angle=grad[i][j], response=harris[i][j], size=10)\n",
    "                  keypoints.append(temp_keypoint)\n",
    "        return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarrisKeypointDetector(KeypointDetector):\n",
    "    def computeHarrisValues(self, srcImage):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - srcImage: Grayscale image (float32) with values in [0, 1], shape (is, cols).\n",
    "        Output:\n",
    "          - harrisImage: numpy array of the same shape containing the Harris corner strength.\n",
    "          - orientationImage: numpy array (same shape) containing gradient orientation (in degrees).\n",
    "        Parameter hints:\n",
    "          - Use ndimage.sobel to compute image gradients Ix and Iy.\n",
    "          - Compute Ixx, Ixy, Iyy, and smooth them with a Gaussian filter.\n",
    "          - Compute the determinant (det = Ixx * Iyy - Ixy^2) and trace (Ixx + Iyy).\n",
    "          - Use a formula (e.g., det - k*(trace)^2 or a variant) to get the response.\n",
    "          - Calculate gradient orientation using np.arctan2(Iy, Ix) and convert to degrees.\n",
    "        \"\"\"\n",
    "        # TODO: Compute Harris corner responses and gradient orientations.\n",
    "\n",
    "        sobel_x = ndimage.sobel(srcImage,axis=0,mode='reflect')\n",
    "        sobel_y = ndimage.sobel(srcImage,axis=1,mode='reflect')\n",
    "        sobel_x2 = np.square(sobel_x)\n",
    "        sobel_y2 = np.square(sobel_y)\n",
    "        sobel_xy = np.multiply(sobel_x,sobel_y)\n",
    "        sobel_x2_gaussian = cv2.GaussianBlur(sobel_x2,ksize=5,sigma=0.5)\n",
    "        sobel_y2_gaussian = cv2.GaussianBlur(sobel_y2,ksize=5,sigma=0.5)\n",
    "        sobel_xy_gaussian = cv2.GaussianBlur(sobel_xy,ksize=5,sigma=0.5)\n",
    "\n",
    "        height,width = srcImage.shape\n",
    "\n",
    "        Harris_response = np.zeros((height,width), np.float32)\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                M_bar = np.array([[sobel_x2_gaussian[i][j], sobel_xy_gaussian[i][j]], [sobel_xy_gaussian[i][j], sobel_y2_gaussian[i][j]]])\n",
    "                Harris_response[i][j] = np.linalg.det(M_bar) - (0.1 * np.square(np.trace(M_bar)))\n",
    "        \n",
    "        grad_orien = np.arctan2(sobel_y, sobel_x) * 180 / np.pi\n",
    "\n",
    "        return Harris_response,grad_orien\n",
    "\n",
    "    def computeLocalMaxima(self, harrisImage):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - harrisImage: numpy array with the Harris response at each pixel.\n",
    "        Output:\n",
    "          - destImage: Boolean numpy array of the same shape, where True indicates \n",
    "            the pixel is the local maximum within a 7x7 neighborhood.\n",
    "        Parameter hints:\n",
    "          - Use ndimage.maximum_filter to get the maximum value in a 7x7 window.\n",
    "          - Compare the original harrisImage with the filtered image.\n",
    "        \"\"\"\n",
    "        # TODO: Implement local maximum detection.\n",
    "        filterd_image = ndimage.maximum_filter(harrisImage, size=7)\n",
    "        \n",
    "        height, width = harrisImage.shape\n",
    "        destImage = np.zeros((height,width), dtype=bool)\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if filterd_image[i][j] == harrisImage[i][j]:\n",
    "                    destImage[i][j]=True\n",
    "                else:\n",
    "                    destImage[i][j]=False\n",
    "        return destImage\n",
    "\n",
    "    def detectKeypoints(self, image):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image with pixel values in [0, 255].\n",
    "        Output:\n",
    "          - A list of cv2.KeyPoint objects, each with:\n",
    "              • pt: (x, y) coordinates,\n",
    "              • angle: gradient orientation (in degrees) at that point,\n",
    "              • response: Harris response at that point,\n",
    "              • size: fixed to 10.\n",
    "        Parameter hints:\n",
    "          - Convert image to float32 and normalize to [0,1], then convert to grayscale.\n",
    "          - Call computeHarrisValues to obtain harrisImage and orientationImage.\n",
    "          - Call computeLocalMaxima to get a boolean mask for local maxima.\n",
    "          - Iterate over the image; for each pixel that is a local maximum, create a keypoint.\n",
    "        \"\"\"\n",
    "        # TODO: Implement keypoint detection using the Harris method.\n",
    "        image_float32 = image.astype(np.float32) / 255\n",
    "        image_gray = cv2.cvtColor(image_float32,cv2.COLOR_BGR2GRAY)\n",
    "        harris,grad = self.computeHarrisValues(image_gray)\n",
    "        maxima = self.computeLocalMaxima(harris)\n",
    "\n",
    "        height,width = image_gray.shape\n",
    "\n",
    "        keypoints = []\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "              if maxima[i][j] == True:\n",
    "                  temp_keypoint = cv2.KeyPoint(x=j, y=i, angle=grad[i][j], response=harris[i][j], size=10)\n",
    "                  keypoints.append(temp_keypoint)\n",
    "        return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBKeypointDetector(KeypointDetector):\n",
    "    def detectKeypoints(self, image):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "        Output:\n",
    "          - A list of keypoints detected using OpenCV's ORB.\n",
    "        \"\"\"\n",
    "        detector = cv2.ORB_create()\n",
    "        return detector.detect(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature descriptors #########################################################\n",
    "\n",
    "class FeatureDescriptor(object):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "          - keypoints: list of detected keypoints.\n",
    "        Output:\n",
    "          - A numpy array of descriptors with shape: (number of keypoints, descriptor dimension).\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeatureDescriptor(FeatureDescriptor):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "          - keypoints: list of keypoints.\n",
    "        Output:\n",
    "          - desc: A (K, 25) numpy array where each descriptor is a flattened 5x5 intensity window.\n",
    "        Parameter hints:\n",
    "          - Convert the image to float32, normalize to [0, 1], and convert to grayscale.\n",
    "          - For each keypoint (x, y), extract a 5x5 patch centered at (x, y).\n",
    "          - If the patch goes beyond the image borders, fill those areas with zeros.\n",
    "        \"\"\"        \n",
    "        image_float32 = image.astype(np.float32) / 255\n",
    "        image_gray = cv2.cvtColor(image_float32,cv2.COLOR_BGR2GRAY)\n",
    "        key_len = len(keypoints)\n",
    "        height, width = image_gray.shape\n",
    "\n",
    "        descriptors = np.zeros((key_len,25))\n",
    "        for i in range(key_len):\n",
    "          x, y = keypoints[i].pt # get the col and row of the keypoints\n",
    "          for j in range(25):\n",
    "            #j / 5 : row number(from 0 to 4)\n",
    "            #j % 5 : col number(from 0 to 4)\n",
    "            if y + (j / 5 - 2) >= 0 and y + (j / 5 - 2) < height and x + (j % 5 - 2) >=0 and x + (j % 5 - 2) < width:\n",
    "              descriptors[i][j] = image_gray[y + (j / 5 - 2)][x + (j % 5 - 2)]\n",
    "\n",
    "        return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOPSFeatureDescriptor(FeatureDescriptor):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "          - keypoints: list of keypoints.\n",
    "        Output:\n",
    "          - desc: A (K, windowSize^2) numpy array, e.g., with windowSize = 8.\n",
    "        Parameter hints:\n",
    "          - Normalize image and convert to grayscale, then apply Gaussian filtering.\n",
    "          - For each keypoint, compute an affine transformation that maps a 40x40 window\n",
    "            around the keypoint to an 8x8 window based on its position and orientation.\n",
    "          - Use cv2.warpAffine to sample the transformed window.\n",
    "          - Normalize the resulting descriptor (zero mean, unit variance; if variance is too small, set descriptor to zero).\n",
    "\n",
    "        问题在于，cv2.warpAffine只接受2*3的矩阵，这和正常的矩阵是不一样的，所以我准备加一个函数来去掉最后一行，而transformation里生成的则是3*3\n",
    "        的矩阵，以方便我们进行矩阵运算\n",
    "        这里还有一个问题，在旋转矩阵的时候PPT里的方法是R[x,y],但warpaffine里面其实是[x,y]R，所以旋转矩阵是转置\n",
    "        最后，实现**绕一点旋转**的方法就是平移*旋转*平移的逆矩阵\n",
    "        \"\"\"\n",
    "        # TODO: Implement the MOPS feature descriptor.\n",
    "        image_float32 = image.astype(np.float32) / 255\n",
    "        image_gray = cv2.cvtColor(image_float32,cv2.COLOR_BGR2GRAY)\n",
    "        image_gray_gaussian = cv2.GaussianBlur(image,ksize=5)\n",
    "\n",
    "        windowSize = 8\n",
    "        key_len = len(keypoints)\n",
    "        height, width = image_gray.shape\n",
    "\n",
    "        desc = np.zeros[key_len,windowSize*windowSize]\n",
    "\n",
    "        for i in key_len:\n",
    "          angle = -1 * keypoints[i].angle\n",
    "          x, y = keypoints[i].pt\n",
    "          angle_in_radian = math.radians(angle)\n",
    "\n",
    "          s_matrix = transformations.get_scale_mx(0.2,0.2)\n",
    "          translation = transformations.get_trans_mx(np.array([x,y]))\n",
    "          translation_inverse = np.linalg.inv(translation)\n",
    "          r_matrix = transformations.get_rot_mx(angle_in_radian)\n",
    "          final_matrix = np.dot(np.dot(np.dot(translation,r_matrix),s_matrix),translation_inverse)\n",
    "\n",
    "          image_affined = cv2.warpAffine(image_gray_gaussian,final_matrix,dsize=(width,height))\n",
    "          for j in range(64):\n",
    "            if y + (j / 8 - 3) >= 0 and y + (j / 8 - 3) < height and x + (j % 8 - 3) >=0 and x + (j % 8 - 3) < width:\n",
    "              desc[i,j] = image_affined[y + (j / 8 - 3)][x + (j % 8 - 3)]\n",
    "          return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBFeatureDescriptor(FeatureDescriptor):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Use OpenCV's ORB to compute descriptors.\n",
    "        \n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "          - keypoints: list of keypoints.\n",
    "        Output:\n",
    "          - A numpy array of descriptors with shape (K, 128).\n",
    "        \"\"\"\n",
    "        descriptor = cv2.ORB_create()\n",
    "        kps, desc = descriptor.compute(image, keypoints)\n",
    "        if desc is None:\n",
    "            desc = np.zeros((0, 128))\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeatureDescriptor(FeatureDescriptor):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - image: uint8 BGR image.\n",
    "          - keypoints: list of keypoints.\n",
    "        Output:\n",
    "          - A custom descriptor numpy array with shape (K, descriptor_dimension).\n",
    "        Hint:\n",
    "          - You may combine ideas from SimpleFeatureDescriptor and MOPSFeatureDescriptor.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('NOT IMPLEMENTED')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature matchers ############################################################\n",
    "\n",
    "class FeatureMatcher(object):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - desc1: numpy array of shape (n, d) representing descriptors for image 1.\n",
    "          - desc2: numpy array of shape (m, d) representing descriptors for image 2.\n",
    "        Output:\n",
    "          - A list of cv2.DMatch objects. For each match, set:\n",
    "              • queryIdx: index in desc1,\n",
    "              • trainIdx: index in desc2,\n",
    "              • distance: distance between descriptors.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluateMatch(features1, features2, matches, h):\n",
    "        \"\"\"\n",
    "        Evaluate matches using a ground-truth homography.\n",
    "        Input:\n",
    "          - features1: keypoints from image 1.\n",
    "          - features2: keypoints from image 2.\n",
    "          - matches: list of cv2.DMatch objects.\n",
    "          - h: homography matrix (array of 9 elements).\n",
    "        Output:\n",
    "          - Average SSD distance between transformed and actual keypoint positions.\n",
    "        \"\"\"\n",
    "        d = 0\n",
    "        n = 0\n",
    "        for m in matches:\n",
    "            id1, id2 = m.queryIdx, m.trainIdx\n",
    "            ptOld = np.array(features2[id2].pt)\n",
    "            ptNew = FeatureMatcher.applyHomography(features1[id1].pt, h)\n",
    "            d += np.linalg.norm(ptNew - ptOld)\n",
    "            n += 1\n",
    "        return d / n if n != 0 else 0\n",
    "\n",
    "    @staticmethod\n",
    "    def applyHomography(pt, h):\n",
    "        \"\"\"\n",
    "        Transform a point using a homography.\n",
    "        Input:\n",
    "          - pt: (x, y) tuple.\n",
    "          - h: homography vector (length 9).\n",
    "        Output:\n",
    "          - Transformed (x, y) as a numpy array.\n",
    "        \"\"\"\n",
    "        x, y = pt\n",
    "        d = h[6]*x + h[7]*y + h[8]\n",
    "        return np.array([(h[0]*x + h[1]*y + h[2]) / d,\n",
    "                         (h[3]*x + h[4]*y + h[5]) / d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDFeatureMatcher(FeatureMatcher):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - desc1: numpy array with shape (n, d).\n",
    "          - desc2: numpy array with shape (m, d).\n",
    "        Output:\n",
    "          - A list of cv2.DMatch objects using SSD (Euclidean distance) for nearest-neighbor matching.\n",
    "        Parameter hints:\n",
    "          - Use scipy.spatial.distance.cdist to compute the distance matrix.\n",
    "          - For each descriptor in desc1, find the closest descriptor in desc2.\n",
    "        \"\"\"\n",
    "        # TODO: Implement SSD-based feature matching.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatioFeatureMatcher(FeatureMatcher):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          - desc1: numpy array with shape (n, d).\n",
    "          - desc2: numpy array with shape (m, d).\n",
    "        Output:\n",
    "          - A list of cv2.DMatch objects using the ratio test.\n",
    "        Parameter hints:\n",
    "          - For each descriptor in desc1, compute distances to all descriptors in desc2.\n",
    "          - Identify the two nearest neighbors and compute the distance ratio.\n",
    "          - Use the ratio as the matching score.\n",
    "        \"\"\"\n",
    "        # TODO: Implement ratio test matching.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"images/left.jpg\")\n",
    "image_float32 = image.astype(np.float32) / 255\n",
    "image_gray = cv2.cvtColor(image_float32,cv2.COLOR_BGR2GRAY)\n",
    "image_gray_gaussian = cv2.GaussianBlur(image_gray,ksize=(5,5),sigmaX=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gray_gaussian',image_gray_gaussian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   4   5   8  10]\n",
      " [ 19 198 239 748 808]]\n"
     ]
    }
   ],
   "source": [
    "list = np.array([\n",
    "    [1,5,4,8,10],\n",
    "    [19,198,239,808,748]\n",
    "])\n",
    "listSorted = np.sort(list)\n",
    "print(listSorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
